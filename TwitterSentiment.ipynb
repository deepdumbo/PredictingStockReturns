{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment\n",
    "##### Amy Ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Prepare for training tweets with mood\n",
    "#df = pd.read_csv(\"Data/SocialMediaData/training.1600000.processed.noemoticon.csv\",header=None)\n",
    "#df = df.rename(columns = {0:'motion',5:\"tweet\"})\n",
    "#df = df[df[\"motion\"]==4][\"tweet\"]\n",
    "# save as txt\n",
    "#df.to_csv(r'positive.txt', header=None, index=None, sep=' ', mode='a')\n",
    "#df = df[df[\"motion\"]==0][\"tweet\"]\n",
    "# save as txt\n",
    "#df.to_csv(r'negative.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "Training tweets download from http://help.sentiment140.com/for-students/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 512 µs, sys: 325 µs, total: 837 µs\n",
      "Wall time: 571 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%cython\n",
    "from gensim.models import doc2vec\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "## postive model\n",
    "def split_sentence (sentence):\n",
    "    return re.split('\\W+',sentence)\n",
    "class MyDocs(object):\n",
    "    def __iter__(self):\n",
    "        for i, text in enumerate(open('train_set/positive.txt')): # doesn't use brand name\n",
    "            yield doc2vec.LabeledSentence(words=split_sentence(text), tags=['%s' % i])\n",
    "            # Train the doc2vec model\n",
    "cdef pos = MyDocs()\n",
    "model = doc2vec.Doc2Vec(pos, size = 200, window = 8, min_count = 5, workers = 4)\n",
    "model.save('positive_tweets.model')# save the model\n",
    "#model = doc2vec.Doc2Vec.load('cab_tweets.model')\n",
    "\n",
    "## negative model\n",
    "def split_sentence (sentence):\n",
    "    return re.split('\\W+',sentence)\n",
    "class MyDocs(object):\n",
    "    def __iter__(self):\n",
    "        for i, text in enumerate(open('train_set/negative.txt')): # doesn't use brand name\n",
    "            yield doc2vec.LabeledSentence(words=split_sentence(text), tags=['%s' % i])\n",
    "            # Train the doc2vec model\n",
    "cdef neg = MyDocs()\n",
    "model = doc2vec.Doc2Vec(neg, size = 200, window = 8, min_count = 5, workers = 4)\n",
    "model.save('negative_tweets.model')# save the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bulid models\n",
    "### 1. CAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "model1 = doc2vec.Doc2Vec.load('positive_tweets.model')\n",
    "model2 = doc2vec.Doc2Vec.load('negative_tweets.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0173258 , -0.00898504, -0.00372691, ..., -0.04584163,\n",
       "         0.04676172, -0.00129063],\n",
       "       [-0.00223486,  0.02191991,  0.03007294, ...,  0.021487  ,\n",
       "        -0.00660933, -0.0134338 ],\n",
       "       [-0.01097532, -0.01810212, -0.02172616, ...,  0.00685231,\n",
       "         0.01789958,  0.00049202],\n",
       "       ..., \n",
       "       [ 0.05336217,  0.00263875, -0.00278048, ...,  0.01692542,\n",
       "         0.03695101,  0.02515182],\n",
       "       [ 0.02517324,  0.03924625, -0.02224799, ..., -0.01132001,\n",
       "        -0.00593403,  0.04400497],\n",
       "       [-0.0551214 , -0.02106871, -0.02813808, ...,  0.00797126,\n",
       "         0.05846385, -0.04289546]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the vector of search term according to our model\n",
    "import numpy as np\n",
    "cab_pos = np.zeros((17800, 200))\n",
    "for i,text in enumerate(open(\"train_set/cab_tweets.txt\")): # input search terms \n",
    "    cab_pos[i]=model1.infer_vector(split_sentence(text))   \n",
    "cab_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01521745,  0.02379482,  0.00525517, ...,  0.0085166 ,\n",
       "         0.04483327,  0.00420388],\n",
       "       [ 0.04234859, -0.07045103, -0.00678941, ..., -0.00261229,\n",
       "        -0.00978813,  0.00431221],\n",
       "       [ 0.02446519, -0.06751232, -0.02617534, ..., -0.02577785,\n",
       "        -0.03009019,  0.00126595],\n",
       "       ..., \n",
       "       [-0.04035848,  0.00359454,  0.0385383 , ...,  0.02497121,\n",
       "        -0.00496958,  0.01990214],\n",
       "       [-0.00276907,  0.01855428, -0.006     , ...,  0.01592065,\n",
       "        -0.00485722,  0.00648402],\n",
       "       [-0.02652839,  0.03481127, -0.01361123, ..., -0.05516719,\n",
       "        -0.05775858, -0.04353976]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab_neg = np.zeros((17800, 200))\n",
    "for i,text in enumerate(open(\"train_set/cab_tweets.txt\")): # input search terms \n",
    "    cab_neg[i]=model2.infer_vector(split_sentence(text))   \n",
    "cab_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.DKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03769807, -0.05903878,  0.03301163, ..., -0.04514879,\n",
       "         0.01143621, -0.0092718 ],\n",
       "       [ 0.03541106,  0.06419629,  0.02617208, ..., -0.03641075,\n",
       "        -0.03344924,  0.06227129],\n",
       "       [ 0.05381933,  0.06853318,  0.0335772 , ..., -0.03769714,\n",
       "        -0.0425928 ,  0.0616048 ],\n",
       "       ..., \n",
       "       [-0.05196267,  0.0226444 ,  0.02209938, ..., -0.02884795,\n",
       "         0.01701822,  0.01468133],\n",
       "       [-0.00889524,  0.00961463, -0.0320751 , ...,  0.02887218,\n",
       "         0.01376016,  0.00777442],\n",
       "       [-0.02629085,  0.03822378,  0.04691299, ..., -0.03198734,\n",
       "        -0.01330235,  0.00199453]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dks_pos = np.zeros((26480, 200))\n",
    "for i,text in enumerate(open(\"train_set/dks_tweets.txt\")): # input search terms \n",
    "    dks_pos[i]=model1.infer_vector(split_sentence(text))   \n",
    "dks_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04076815,  0.01920363,  0.03726069, ...,  0.00924385,\n",
       "         0.06227892,  0.0344903 ],\n",
       "       [ 0.05956909,  0.04329693,  0.01750396, ..., -0.03252006,\n",
       "        -0.03920196,  0.08062712],\n",
       "       [ 0.03949922,  0.11058771,  0.01037455, ..., -0.05932995,\n",
       "        -0.01978178,  0.05335316],\n",
       "       ..., \n",
       "       [-0.03477366,  0.01279694,  0.00508458, ..., -0.00918794,\n",
       "        -0.00195322, -0.02989849],\n",
       "       [-0.0089085 ,  0.01510515, -0.02993284, ...,  0.03266199,\n",
       "         0.02061392,  0.00195406],\n",
       "       [-0.03854375,  0.03387105,  0.04029921, ..., -0.02916235,\n",
       "        -0.00458328, -0.00497512]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dks_neg = np.zeros((26480, 200))\n",
    "for i,text in enumerate(open(\"train_set/dks_tweets.txt\")): # input search terms \n",
    "    dks_neg[i]=model1.infer_vector(split_sentence(text))   \n",
    "dks_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the cosin distance to check the change of moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate the cosin distance between 2 vectors to generate the 3rd features\n",
    "# Compute the cosine similarity values between the input text and all archived reviews\n",
    "# cossims_with_input = map(lambda v: cossim(input_vec, v), model.docvecs) \n",
    "# need to chaneg the code into rows: calculate the cosin distance between the vectors in same rows\n",
    "\n",
    "# Calculate the cosine similarity between two vecotrs \n",
    "def cossim(v1, v2):\n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / np.sqrt(np.dot(v2, v2))\n",
    "\n",
    "cossims_cab=np.zeros((17800,1))\n",
    "for i in range(17800):\n",
    "    cossims_cab[i] = cossim(cab_pos[i], cab_neg[i])\n",
    "np.savetxt(\"cab_sentiment.csv\",cossims_cab, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cossims_dks=np.zeros((26480,1))\n",
    "for i in range(26480):\n",
    "    cossims_dks[i] = cossim(dks_pos[i], dks_neg[i])\n",
    "np.savetxt(\"dks_sentiment.csv\",cossims_dks, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
